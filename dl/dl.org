#+latex_header:                {\section*{\indexname}%
#+latex_header:                 \@mkboth{\MakeUppercase\indexname}%
#+latex_header:                         {\MakeUppercase\indexname}%
#+latex_header:                 \thispagestyle{plain}\parindent\z@
#+latex_header:                 \parskip\z@ \@plus .3\p@\relax
#+latex_header:                 \columnseprule \z@
#+latex_header:                 \columnsep 35\p@
#+latex_header:                 \let\item\@idxitem}
#+latex_header:                {}
#+latex_header: \makeatother

#+latex_header: \usepackage{glossaries}
#+latex_header: \makeglossaries
#+latex_header_extra: \newglossaryentry{acronym}{name={acronym},description={An acronym is an abbreviation used as a word which is formed from the initial components in a phrase or a word. Usually these components are individual letters (as in NATO or laser) or parts of words or names (as in Benelux)}}
#+latex_header_extra: \newacronym{tla}{TLA}{Three Letter Acronym}

\maketitle
\tableofcontents

* LSTMs
** LSTM(Long Short Term Memory networks)
  One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task.

  Sometimes, we only need to look at recent information to perform the present task(e.g.: The clouds are in the _sky_). But there are also cases where we need more context(e.g.: I grew up in France... I speak fluent _French_)

  Its entirely possible for the gap between the relevant information and the point there is needed to become very large. Unfortunately as the gap grows, RNNs become unable to learn to connect the information. WHY? \\
  This is because when the net is very deep, then will be very difficult to train due to the *exploding and the vanishing gradient problems*. Both problems are caused by RNN's iterative nature, whose gradient is raised to a high power. These iterated matrix powers caused the gradient to grow or to shrink at a rate that is exponential in the numbers of time-steps.

  LSTMs are explicitly designed to avoid the long-term dependency problem.

  The key to LSTMs is the *cell state*.

  Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.
  [[./figures/pointwise multiplication operation.png]]
  An LSTM has three of these gates, *to protect and control the cell state*.


  In theory, RNNs are absolutely capable of handling such "long-term dependencies." A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by Hochreiter (1991) [German] and Bengio, et al. (1994), who found some pretty fundamental reasons why it might be difficult. Thankfully, LSTMs don’t have this problem! \cite{lstm1}

  #+CAPTION: Forget Gate(decide what old information to thrown away from the cell state)
  [[./figures/lstm1.png]]

  $i_t$: decides which values will update.  \\
  $\tilde{C_t}$: decides new candidate values could be added to the state.
  #+CAPTION: Input Gate(decide what new information to store in the cell state)
  [[./figures/lstm2.png]]


  #+CAPTION: Update the old state to new state.
  [[./figures/lstm3.png]]

  #+CAPTION: Union forget gate and input gate
  [[./figures/lstm3.5.png]]

  #+CAPTION: Output Gate(decide what information to output)
  [[./figures/lstm4.png]]

** Variants On LSTM1
   [[./figures/lstmV1.png]]

   [[./figures/lstmV2.png]]

** GRU(Gated Recurrent Unit)
   It combines the forget and input gates into a single "update gate"
   #+CAPTION: GRU(Gated Recurrent Unit)
   [[./figures/gru.png]]
** An Empirical Exploration of Recurrent Network Architectures
   Standard RNNs suffer from both exploding and vanishing gradients. Both problems caused by
  This is because when the net is very deep, then will be very difficult to train due to the *exploding and the vanishing gradient problems*. Both problems are caused by RNN's iterative nature, whose gradient is raised to a high power. These iterated matrix powers caused the gradient to grow or to shrink at a rate that is exponential in the numbers of time-steps.


   文章作者做了多组实验检测各种不同结构的RNN在不同的问题上的表现, 得到的结论包括:

    1. GRU在除了语言模型的其他地方比LSTM表现好
    2. LSTM with dropout在语言模型上表现好, 有大的遗忘门偏置后表现更好
    3. 在LSTM中, 各个门的重要性为: 遗忘门>输入门>输出门
    4. 遗忘门在除了语言模型外的情况下影响非常大

    语言模型的长期依赖效应强于其他场景
* References
<<bibliography link>>

bibliographystyle:unsrt
bibliography:DeepLearning.bib

#  LocalWords:  Zhenkai indexname MakeUppercase thispagestyle parindent parskip
#  LocalWords:  columnseprule columnsep makeatother usepackage makeglossaries
#  LocalWords:  newglossaryentry newacronym tla TLA maketitle tableofcontents
#  LocalWords:  png lstm et al
