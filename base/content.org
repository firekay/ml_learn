# #+OPTIONS: ^:nil
#+SETUPFILE: https://fniessen.github.io/org-html-themes/setup/theme-readtheorg.setup
#+author: Xu Zhenkai
#+title: base ml
* What Is ML
   1. The field of machine learning is concerned with the question of how to construct *computer programs* that *automatically improve* with experience. \\
    A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.
   2. Vast amounts of data are being generated in many fields, and the statisticiansâ€™s job is to make sense of it all: to extract important patterns and trends, and to understand â€œwhat the data saysâ€. We call this learning from data. \\
      The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   3. One of the most interesting features of machine learning is that it lies on the boundary of several different academic disciplines, principally computer science, statistics, mathematics, and engineering. â€¦ machine learning is usually studied as part of artificial intelligence, which puts it firmly into computer science â€¦understanding why these algorithms work requires a certain amount of statistical and mathematical sophistication that is often missing from computer science undergraduates.
   4. Machine Learning is Hacking + Math & Statistics.

* Class Imbalance
  ç±»åˆ«ä¸å¹³è¡¡ class-imbalance

  ä¸»è¦ä»‹ç»äº†åˆ†ç±»ä¸­ç±»åˆ«ä¸å‡è¡¡æ—¶å­¦ä¹ ä¸­å¸¸ç”¨çš„ç®—æ³•åŠè¯„ä»·æŒ‡æ ‡ï¼Œç®—æ³•ä¸»è¦ä»æ•°æ®å’Œæ¨¡å‹ä¸¤ä¸ªå±‚é¢ä»‹ç»ï¼Œæ•°æ®å±‚é¢çš„ç®—æ³•ä¸»è¦å…³äºè¿‡é‡‡æ ·å’Œæ¬ é‡‡æ ·ä»¥åŠæ”¹è¿›çš„ç®—æ³•ï¼Œæ¨¡å‹æ–¹é¢ä¸»è¦è®²è§£äº†åŸºäºä»£ä»·çš„æ•æ„Ÿå­¦ä¹ ã€‚è¯„ä»·æŒ‡æ ‡ä¸»è¦è®²è§£äº† F1 åº¦é‡ã€G-Mean å’Œ ROC æ›²çº¿ AUC é¢ç§¯ã€‚

  å¦‚æœä¸åŒç±»åˆ«çš„è®­ç»ƒæ ·ä¾‹æ•°ç›®ç¨æœ‰å·®åˆ«ï¼Œé€šå¸¸å½±å“ä¸å¤§ï¼Œä½†è‹¥å·®åˆ«å¾ˆå¤§ï¼Œåˆ™ä¼šå¯¹å­¦ä¹ è¿‡ç¨‹é€ æˆå›°æ‰°ã€‚ä¾‹å¦‚æœ‰ 998 ä¸ªåä¾‹ï¼Œä½†æ˜¯æ­£ä¾‹åªæœ‰ 2 ä¸ªï¼Œé‚£ä¹ˆå­¦ä¹ æ–¹æ³•åªéœ€è¦è¿”å›ä¸€ä¸ªæ°¸è¿œå°†æ–°æ ·æœ¬é¢„æµ‹ä¸ºåä¾‹çš„å­¦ä¹ å™¨ï¼Œå°±èƒ½è¾¾åˆ° 99.8%çš„ç²¾åº¦ï¼›ç„¶è€Œè¿™æ ·çš„å­¦ä¹ å™¨å¾€å¾€æ²¡æœ‰ä»·å€¼ï¼Œå› ä¸ºå®ƒä¸èƒ½é¢„æµ‹å‡ºä»»ä½•æ­£ä¾‹ã€‚

  ç±»åˆ«ä¸å¹³è¡¡ï¼ˆclass-imbalanceï¼‰å°±æ˜¯æŒ‡åˆ†ç±»ä»»åŠ¡ä¸­ä¸åŒç±»åˆ«çš„è®­ç»ƒæ ·ä¾‹æ•°ç›®å·®åˆ«å¾ˆå¤§çš„æƒ…å†µã€‚åœ¨ç°å®çš„åˆ†ç±»å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä¼šé‡åˆ°ç±»åˆ«ä¸å¹³è¡¡ï¼Œä¾‹å¦‚åœ¨é€šè¿‡æ‹†åˆ†æ³•è§£å†³å¤šåˆ†ç±»é—®é¢˜æ—¶ï¼Œå³ä½¿åŸå§‹é—®é¢˜ä¸­ä¸åŒç±»åˆ«çš„è®­ç»ƒæ ·ä¾‹æ•°ç›®ç›¸å½“ï¼Œåœ¨ä½¿ç”¨ OvRï¼ˆä¸€å¯¹å…¶ä½™ï¼ŒOne vs. Restï¼Œç®€ç§° OvRï¼‰ã€MvMï¼ˆå¤šå¯¹å¤šï¼ŒMany vs. Manyï¼Œç®€ç§° MvMï¼‰ç­–ç•¥åäº§ç”Ÿçš„äºŒåˆ†ç±»ä»»åŠ¡æ‰”å¯èƒ½å‡ºç°ç±»åˆ«ä¸å¹³è¡¡ç°è±¡.

** è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
*** æ¬ é‡‡æ ·æ–¹æ³•(undersampling)
    ç›´æ¥å¯¹è®­ç»ƒé›†ä¸­å¤šæ•°ç±»æ ·æœ¬è¿›è¡Œâ€œæ¬ é‡‡æ ·â€ï¼ˆundersamplingï¼‰ï¼Œå³å»é™¤ä¸€äº›å¤šæ•°ç±»ä¸­çš„æ ·æœ¬ä½¿å¾—æ­£ä¾‹ã€åä¾‹æ•°ç›®æ¥è¿‘ï¼Œç„¶åå†è¿›è¡Œå­¦ä¹ [fn:5]ã€‚
**** éšæœºæ¬ é‡‡æ ·æ–¹æ³•

     éšæœºæ¬ é‡‡æ ·é¡¾åæ€ä¹‰å³ä»å¤šæ•°ç±» $S_{maj}$ ä¸­éšæœºé€‰æ‹©ä¸€äº›æ ·æ ·æœ¬ç»„æˆæ ·æœ¬é›† *E* ã€‚ç„¶åå°†æ ·æœ¬é›† *E* ä» $S_{maj}$ ä¸­ç§»é™¤ã€‚æ–°çš„æ•°æ®é›† $S_{new-maj}=S_{maj}-E$ ã€‚

     - ç¼ºç‚¹

       éšæœºæ¬ é‡‡æ ·æ–¹æ³•é€šè¿‡æ”¹å˜å¤šæ•°ç±»æ ·æœ¬æ¯”ä¾‹ä»¥è¾¾åˆ°ä¿®æ”¹æ ·æœ¬åˆ†å¸ƒçš„ç›®çš„ï¼Œä»è€Œä½¿æ ·æœ¬åˆ†å¸ƒè¾ƒä¸ºå‡è¡¡ï¼Œä½†æ˜¯è¿™ä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ã€‚å¯¹äºéšæœºæ¬ é‡‡æ ·ï¼Œç”±äºé‡‡æ ·çš„æ ·æœ¬é›†åˆè¦å°‘äºåŸæ¥çš„æ ·æœ¬é›†åˆï¼Œå› æ­¤ä¼šé€ æˆä¸€äº›ä¿¡æ¯ç¼ºå¤±ï¼Œå³å°†å¤šæ•°ç±»æ ·æœ¬åˆ é™¤æœ‰å¯èƒ½ä¼šå¯¼è‡´åˆ†ç±»å™¨ä¸¢å¤±æœ‰å…³å¤šæ•°ç±»çš„é‡è¦ä¿¡æ¯ã€‚

     ä¸ºäº†å…‹æœéšæœºæ¬ é‡‡æ ·æ–¹æ³•å¯¼è‡´çš„ä¿¡æ¯ç¼ºå¤±é—®é¢˜ï¼Œåˆè¦ä¿è¯ç®—æ³•è¡¨ç°å‡ºè¾ƒå¥½çš„ä¸å‡è¡¡æ•°æ®åˆ†ç±»æ€§èƒ½ï¼Œå‡ºç°äº†æ¬ é‡‡æ ·æ³•ä»£è¡¨æ€§çš„ç®—æ³• *EasyEnsemble* å’Œ *BalanceCascade* ç®—æ³•ã€‚
**** æ¬ é‡‡æ ·ä»£è¡¨æ€§ç®—æ³•-EasyEnsemble \cite{4717268}

     ç®—æ³•æ­¥éª¤ï¼š
      1. ä»å¤šæ•°ç±»ä¸­æœ‰æ”¾å›çš„éšæœºé‡‡æ · n æ¬¡ï¼Œæ¯æ¬¡é€‰å–ä¸å°‘æ•°ç±»æ•°ç›®ç›¸è¿‘çš„æ ·æœ¬ä¸ªæ•°ï¼Œé‚£ä¹ˆå¯ä»¥å¾—åˆ° n ä¸ªæ ·æœ¬é›†åˆè®°ä½œã€‚
      2. ç„¶åï¼Œå°†æ¯ä¸€ä¸ªå¤šæ•°ç±»æ ·æœ¬çš„å­é›†ä¸å°‘æ•°ç±»æ ·æœ¬åˆå¹¶å¹¶è®­ç»ƒå‡ºä¸€ä¸ªæ¨¡å‹ï¼Œå¯ä»¥å¾—åˆ° n ä¸ªæ¨¡å‹ã€‚
      3. æœ€ç»ˆå°†è¿™äº›æ¨¡å‹ç»„åˆå½¢æˆä¸€ä¸ªé›†æˆå­¦ä¹ ç³»ç»Ÿï¼Œæœ€ç»ˆçš„æ¨¡å‹ç»“æœæ˜¯è¿™ n ä¸ªæ¨¡å‹çš„å¹³å‡å€¼ã€‚
**** æ¬ é‡‡æ ·ä»£è¡¨æ€§ç®—æ³•-BalanceCascade \cite{4717268}

     BalanceCascade ç®—æ³•åŸºäº Adaboostï¼Œå°† Adaboost ä½œä¸ºåŸºåˆ†ç±»å™¨ï¼Œå…¶æ ¸å¿ƒæ€è·¯æ˜¯ï¼š
      1. åœ¨æ¯ä¸€è½®è®­ç»ƒæ—¶éƒ½ä½¿ç”¨å¤šæ•°ç±»ä¸å°‘æ•°ç±»æ•°é‡ç›¸ç­‰çš„è®­ç»ƒé›†ï¼Œè®­ç»ƒå‡ºä¸€ä¸ª Adaboost åŸºåˆ†ç±»å™¨ã€‚
      2. ç„¶åä½¿ç”¨è¯¥åˆ†ç±»å™¨å¯¹å…¨ä½“å¤šæ•°ç±»è¿›è¡Œé¢„æµ‹ï¼Œé€šè¿‡æ§åˆ¶åˆ†ç±»é˜ˆå€¼æ¥æ§åˆ¶å‡æ­£ä¾‹ç‡ï¼ˆFalse Positive Rateï¼‰,å°†æ‰€æœ‰åˆ¤æ–­æ­£ç¡®çš„ç±»åˆ é™¤ã€‚
      3. æœ€åï¼Œè¿›å…¥ä¸‹ä¸€è½®è¿­ä»£ä¸­ï¼Œç»§ç»­é™ä½å¤šæ•°ç±»æ•°é‡ã€‚
     #+CAPTION: BalanceCascade Algorithms
     file:figures/BalanceCascade.png
*** è¿‡é‡‡æ ·æ–¹æ³•
    å¯¹è®­ç»ƒé›†é‡Œçš„å°‘æ•°ç±»è¿›è¡Œâ€œè¿‡é‡‡æ ·â€ï¼ˆoversamplingï¼‰ï¼Œå³å¢åŠ ä¸€äº›å°‘æ•°ç±»æ ·æœ¬ä½¿å¾—æ­£ã€åä¾‹æ•°ç›®æ¥è¿‘ï¼Œç„¶åå†è¿›è¡Œå­¦ä¹ ã€‚
**** éšæœºè¿‡é‡‡æ ·æ–¹æ³•

     éšæœºè¿‡é‡‡æ ·æ˜¯åœ¨å°‘æ•°ç±» $S_{min}$ ä¸­éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬ï¼Œç„¶åé€šè¿‡å¤åˆ¶æ‰€é€‰æ‹©çš„æ ·æœ¬ç”Ÿæˆæ ·æœ¬é›† *E* ï¼Œå°†å®ƒä»¬æ·»åŠ åˆ° $S_{min}$ ä¸­æ¥æ‰©å¤§åŸå§‹æ•°æ®é›†ä»è€Œå¾—åˆ°æ–°çš„å°‘æ•°ç±»é›†åˆ $S_{new-min}$ ã€‚æ–°çš„æ•°æ®é›† $S_{new-min} = S_{min} + E$ ã€‚
     - ç¼ºç‚¹

       å¯¹äºéšæœºè¿‡é‡‡æ ·ï¼Œç”±äºéœ€è¦å¯¹å°‘æ•°ç±»æ ·æœ¬è¿›è¡Œå¤åˆ¶æ¥æ‰©å¤§æ•°æ®é›†ï¼Œé€ æˆæ¨¡å‹è®­ç»ƒå¤æ‚åº¦åŠ å¤§ã€‚å¦ä¸€æ–¹é¢ä¹Ÿå®¹æ˜“é€ æˆæ¨¡å‹çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå› ä¸ºéšæœºè¿‡é‡‡æ ·æ˜¯ç®€å•çš„å¯¹åˆå§‹æ ·æœ¬è¿›è¡Œå¤åˆ¶é‡‡æ ·ï¼Œè¿™å°±ä½¿å¾—å­¦ä¹ å™¨å­¦å¾—çš„è§„åˆ™è¿‡äºå…·ä½“åŒ–ï¼Œä¸åˆ©äºå­¦ä¹ å™¨çš„æ³›åŒ–æ€§èƒ½ï¼Œé€ æˆè¿‡æ‹Ÿåˆé—®é¢˜ã€‚

       ä¸ºäº†è§£å†³éšæœºè¿‡é‡‡æ ·ä¸­é€ æˆæ¨¡å‹è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œåˆèƒ½ä¿è¯å®ç°æ•°æ®é›†å‡è¡¡çš„ç›®çš„ï¼Œå‡ºç°äº†è¿‡é‡‡æ ·æ³•ä»£è¡¨æ€§çš„ç®—æ³• *SMOTE* å’Œ *Borderline-SMOTE* ç®—æ³•ã€‚

**** è¿‡é‡‡æ ·ä»£è¡¨æ€§ç®—æ³•-SMOTE \cite{Chawla_2002}

     SMOTE å…¨ç§°æ˜¯ Synthetic Minority Oversampling å³åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯.

     SOMT ç®—æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯å¯¹æ¯ä¸ªå°‘æ•°ç±»æ ·æœ¬ï¼Œä»å®ƒçš„æœ€è¿‘é‚»ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ï¼ˆæ˜¯å°‘æ•°ç±»ä¸­çš„ä¸€ä¸ªæ ·æœ¬ï¼‰ï¼Œç„¶ååœ¨å’Œä¹‹é—´çš„è¿çº¿ä¸Šéšæœºé€‰æ‹©ä¸€ç‚¹ä½œä¸ºæ–°åˆæˆçš„å°‘æ•°ç±»æ ·æœ¬ã€‚

     SMOTE ç®—æ³•åˆæˆæ–°å°‘æ•°ç±»æ ·æœ¬çš„ç®—æ³•æè¿°å¦‚ä¸‹ï¼š
      1. å¯¹äºå°‘æ•°ç±»ä¸­çš„æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œä»¥æ¬§æ°è·ç¦»ä¸ºæ ‡å‡†è®¡ç®—å®ƒåˆ°å°‘æ•°ç±»æ ·æœ¬é›†ä¸­æ‰€æœ‰æ ·æœ¬çš„è·ç¦»ï¼Œå¾—åˆ°å…¶ k è¿‘é‚»ã€‚
      2. æ ¹æ®æ ·æœ¬ä¸å¹³è¡¡æ¯”ä¾‹è®¾ç½®ä¸€ä¸ªé‡‡æ ·æ¯”ä¾‹ä»¥ç¡®å®šé‡‡æ ·å€ç‡ Nï¼Œå¯¹äºæ¯ä¸€ä¸ªå°‘æ•°ç±»æ ·æœ¬ï¼Œä»å…¶ k è¿‘é‚»ä¸­éšæœºé€‰æ‹©è‹¥å¹²ä¸ªæ ·æœ¬ï¼Œå‡è®¾é€‰æ‹©çš„æ˜¯ã€‚
      3. å¯¹äºæ¯ä¸€ä¸ªéšæœºé€‰å‡ºæ¥çš„è¿‘é‚»ï¼Œåˆ†åˆ«ä¸æŒ‰ç…§å¦‚ä¸‹å…¬å¼æ„å»ºæ–°çš„æ ·æœ¬ã€‚ \( x_{new} = x_{i} + rand(0, 1) * (\hat{x_{i}} - x_{i}) \)

     SMOTE ç®—æ³•æ‘’å¼ƒäº†éšæœºè¿‡é‡‡æ ·å¤åˆ¶æ ·æœ¬çš„åšæ³•ï¼Œå¯ä»¥é˜²æ­¢éšæœºè¿‡é‡‡æ ·ä¸­å®¹æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œå®è·µè¯æ˜æ­¤æ–¹æ³•å¯ä»¥æé«˜åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚

     ä½†æ˜¯ SMOTE ç®—æ³•ä¹Ÿå­˜ä»¥ä¸‹ä¸¤ä¸ªç¼ºç‚¹:
      - ç”±äºå¯¹æ¯ä¸ªå°‘æ•°ç±»æ ·æœ¬éƒ½ç”Ÿæˆæ–°æ ·æœ¬ï¼Œå› æ­¤å®¹æ˜“å‘ç”Ÿç”Ÿæˆæ ·æœ¬é‡å çš„é—®é¢˜ã€‚
      - åœ¨ SMOTE ç®—æ³•ä¸­ï¼Œå‡ºç°äº†è¿‡åº¦æ³›åŒ–çš„é—®é¢˜ï¼Œä¸»è¦å½’ç»“äºäº§ç”Ÿåˆæˆæ ·æœ¬çš„æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼ŒSMOTE ç®—æ³•å¯¹äºæ¯ä¸ªåŸå°‘æ•°ç±»æ ·æœ¬äº§ç”Ÿç›¸åŒæ•°é‡çš„åˆæˆæ•°æ®æ ·æœ¬ï¼Œè€Œæ²¡æœ‰è€ƒè™‘å…¶é‚»è¿‘æ ·æœ¬çš„åˆ†å¸ƒç‰¹ç‚¹ï¼Œè¿™å°±ä½¿å¾—ç±»é—´å‘ç”Ÿé‡å¤çš„å¯èƒ½æ€§å¢å¤§ã€‚
     ä¸ºäº†å…‹æœä»¥ä¸Šä¸¤ç‚¹çš„é™åˆ¶ï¼Œå¤šç§ä¸åŒçš„è‡ªé€‚åº”æŠ½æ ·æ–¹æ³•ç›¸ç»§è¢«æå‡ºï¼Œå…¶ä¸­å…·æœ‰ä»£è¡¨æ€§çš„ç®—æ³•åŒ…æ‹¬ Borderline-SMOTE ç®—æ³•ã€‚

**** Borderline-SMOTE ç®—æ³•  \cite{Han_2005}

     å¯¹äº Borderline-SMOTE ç®—æ³•æœ€æ„Ÿå…´è¶£çš„å°±æ˜¯ç”¨äºè¯†åˆ«å°‘æ•°ç±»ç§å­æ ·æœ¬çš„æ–¹æ³•ã€‚åœ¨ Borderline-SMOTE ç®—æ³•ä¸­ï¼Œè¯†åˆ«å°‘æ•°ç±»ç§å­æ ·æœ¬çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

      1. é¦–å…ˆï¼Œå¯¹äºæ¯ä¸ª $x_{i} \subset S_{min}$ ,ç¡®å®šä¸€ç³»åˆ—æœ€è¿‘é‚»æ ·æœ¬é›†ï¼Œæˆè¯¥æ•°æ®é›†ä¸º $S_{i-KNN}$ ï¼Œä¸” $S_{i-KNN} \subset S$ ã€‚
      2. ç„¶åï¼Œå¯¹æ¯ä¸ªæ ·æœ¬ $x_{i}$ ï¼Œåˆ¤æ–­å‡ºæœ€è¿‘é‚»æ ·æœ¬é›†ä¸­å±äºå¤šæ•°ç±»æ ·æœ¬çš„ä¸ªæ•°ï¼Œå³ $|S_{i-KNN} \cap S_{maj}|$ ï¼š
      3. æœ€åï¼Œé€‰æ‹©æ»¡è¶³ä¸‹é¢ä¸ç­‰å¼çš„ã€‚
         \( k/2 < |S_{i-KNN} \cap S_{maj}| < k \)

     ä¸Šé¢å¼å­è¡¨æ˜ï¼Œåªæœ‰æœ€è¿‘é‚»æ ·æœ¬é›†ä¸­å¤šæ•°ç±»å¤šäºå°‘æ•°ç±»çš„é‚£äº› $x_{i}$ æ‰ä¼šè¢«é€‰ä¸­å½¢æˆâ€œå±é™©é›†â€(DANGER)ã€‚å› æ­¤ï¼ŒDANGER é›†ä¸­çš„æ ·æœ¬ä»£è¡¨å°‘æ•°ç±»æ ·æœ¬çš„è¾¹ç•Œï¼ˆæœ€å®¹æ˜“è¢«é”™åˆ†çš„æ ·æœ¬ï¼‰ã€‚ç„¶åå¯¹ DANGER é›†ä¸­ä½¿ç”¨ SMOTE ç®—æ³•åœ¨è¾¹ç•Œé™„è¿‘äº§ç”Ÿäººå·¥åˆæˆå°‘æ•°ç±»æ ·æœ¬ã€‚

     #+CAPTION: åŸºäºåœ¨è¾¹ç•Œä¸Šæ ·æœ¬çš„æ•°æ®å»ºç«‹
     #+NAME: fig.smote_data
     [[file:figures/borderline_smote_data.png]]

     #+CAPTION: Borderline-SMOTE ç®—æ³•æµç¨‹å›¾
     #+NAME: fig.smote_flow
     [[file:figures/borderline_smote_flow.png]]
*** ä»£ä»·æ•æ„Ÿå­¦ä¹ (cost-sensitive learning)

    é‡‡æ ·ç®—æ³•ä»æ•°æ®å±‚é¢è§£å†³ä¸å¹³è¡¡æ•°æ®çš„å­¦ä¹ é—®é¢˜ï¼›åœ¨ç®—æ³•å±‚é¢ä¸Šè§£å†³ä¸å¹³è¡¡æ•°æ®å­¦ä¹ çš„æ–¹æ³•ä¸»è¦æ˜¯åŸºäºä»£ä»·æ•æ„Ÿå­¦ä¹ ç®—æ³•ï¼ˆCost-Sensitive Learning).

    ä»£ä»·æ•æ„Ÿå­¦ä¹ æ–¹æ³•çš„æ ¸å¿ƒè¦ç´ æ˜¯ä»£ä»·çŸ©é˜µ.

      #+CAPTION: ä»£ä»·çŸ©é˜µ
      | çœŸæ˜¯ç±»åˆ« | é¢„æµ‹ç±»åˆ«  | é¢„æµ‹ç±»åˆ«  |
      |          | ç¬¬ 0 ç±»   | ç¬¬ 1 ç±»   |
      |----------+-----------+-----------|
      |        0 | 0         | Cost_{01} |
      |        1 | Cost_{10} | 0         |
**** ä»£ä»·æ•æ„Ÿå­¦ä¹ æ–¹æ³•
     ä»£ä»·æ•æ„Ÿå­¦ä¹ æ–¹æ³•ä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ç§å®ç°æ–¹å¼:
       1. ä»å­¦ä¹ æ¨¡å‹å‡ºå‘
          *å¯¹æŸä¸€å…·ä½“å­¦ä¹ æ–¹æ³•çš„æ”¹é€ * ï¼Œä½¿ä¹‹èƒ½é€‚åº”ä¸å¹³è¡¡æ•°æ®ä¸‹çš„å­¦ä¹ ï¼Œç ”ç©¶è€…ä»¬é’ˆå¯¹ä¸åŒçš„å­¦ä¹ æ¨¡å‹å¦‚æ„ŸçŸ¥æœºã€æ”¯æŒå‘é‡æœºã€å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œç­‰åˆ†åˆ«æå‡ºäº†å…¶ä»£ä»·æ•æ„Ÿçš„ç‰ˆæœ¬ã€‚ä»¥ä»£ä»·æ•æ„Ÿçš„å†³ç­–æ ‘ä¸ºä¾‹ï¼Œå¯ä»¥ä»ä¸‰ä¸ªæ–¹é¢å¯¹å…¶è¿›è¡Œæ”¹é€ ä»¥é€‚åº”ä¸å¹³è¡¡æ•°æ®çš„å­¦ä¹ ï¼Œè¿™ä¸‰ä¸ªæ–¹é¢åˆ†åˆ«æ˜¯å†³ç­–é˜ˆå€¼çš„é€‰æ‹©æ–¹é¢ã€åˆ†è£‚æ ‡å‡†çš„é€‰æ‹©æ–¹é¢ã€å‰ªææ–¹é¢ï¼Œè¿™ä¸‰ä¸ªæ–¹é¢éƒ½å¯ä»¥å°†ä»£ä»·çŸ©é˜µå¼•å…¥ã€‚
       2. ä»è´å¶æ–¯é£é™©ç†è®ºå‡ºå‘
          *æŠŠä»£ä»·æ•æ„Ÿå­¦ä¹ çœ‹æˆæ˜¯åˆ†ç±»ç»“æœçš„ä¸€ç§åå¤„ç†* ï¼ŒæŒ‰ç…§ä¼ ç»Ÿæ–¹æ³•å­¦ä¹ åˆ°ä¸€ä¸ªæ¨¡å‹ï¼Œä»¥å®ç°æŸå¤±æœ€å°ä¸ºç›®æ ‡å¯¹ç»“æœè¿›è¡Œè°ƒæ•´ï¼Œä¼˜åŒ–å…¬å¼å¦‚ä¸‹æ‰€ç¤ºã€‚æ­¤æ–¹æ³•çš„ä¼˜ç‚¹åœ¨äºå®ƒå¯ä»¥ä¸ä¾èµ–æ‰€ç”¨çš„å…·ä½“åˆ†ç±»å™¨ï¼Œä½†æ˜¯ç¼ºç‚¹ä¹Ÿå¾ˆæ˜æ˜¾ï¼Œå®ƒè¦æ±‚åˆ†ç±»å™¨è¾“å‡ºå€¼ä¸ºæ¦‚ç‡ã€‚
       3. ä»é¢„å¤„ç†çš„è§’åº¦å‡ºå‘
          *å°†ä»£ä»·ç”¨äºæƒé‡è°ƒæ•´* ï¼Œä½¿å¾—åˆ†ç±»å™¨æ»¡è¶³ä»£ä»·æ•æ„Ÿçš„ç‰¹æ€§ï¼Œä¸‹é¢è®²è§£ä¸€ç§åŸºäº Adaboost çš„æƒé‡æ›´æ–°ç­–ç•¥ AdaCost ç®—æ³•ã€‚

          AdaCost ç®—æ³•ä¿®æ”¹äº† Adaboost ç®—æ³•çš„æƒé‡æ›´æ–°ç­–ç•¥ï¼Œå…¶åŸºæœ¬æ€æƒ³æ˜¯ *å¯¹ä»£ä»·é«˜çš„è¯¯åˆ†ç±»æ ·æœ¬å¤§å¤§åœ°æé«˜å…¶æƒé‡ï¼Œè€Œå¯¹äºä»£ä»·é«˜çš„æ­£ç¡®åˆ†ç±»æ ·æœ¬é€‚å½“åœ°é™ä½å…¶æƒé‡ï¼Œä½¿å…¶æƒé‡é™ä½ç›¸å¯¹è¾ƒå°ã€‚æ€»ä½“æ€æƒ³æ˜¯ä»£ä»·é«˜æ ·æœ¬æƒé‡å¢åŠ å¾—å¤§é™ä½çš„æ…¢* ã€‚
          å…¶æ ·æœ¬æƒé‡æŒ‰ç…§å¦‚ä¸‹å…¬å¼è¿›è¡Œæ›´æ–°ã€‚å…¶ä¸­ $\beta_{\_}$ å’Œ $\beta_{+}$ åˆ†åˆ«è¡¨ç¤ºæ ·æœ¬è¢«æ­£ç¡®å’Œé”™è¯¯åˆ†ç±»æƒ…å†µä¸‹çš„ $\beta$ çš„å–å€¼ã€‚
          #+CAPTION: Adacost weight update
          [[./figures/adacost.png]]

          #+CAPTION: Adaboost algorithm
          [[./figures/adaboost.png]]
** ä¸å¹³è¡¡å­¦ä¹ çš„è¯„ä»·æ–¹æ³•
   - F1
   - G-Mean
   - ROCæ›²çº¿å’ŒAUCé¢ç§¯
** å¦‚ä½•é€‰æ‹©ç®—æ³•
    1. åœ¨æ­£è´Ÿæ ·æœ¬éƒ½éå¸¸å°‘çš„æƒ…å†µä¸‹ï¼Œåº”è¯¥é‡‡ç”¨æ•°æ®åˆæˆçš„æ–¹å¼ï¼Œä¾‹å¦‚ï¼šSMOTE ç®—æ³•å’Œ Borderline-SMOTE ç®—æ³•ã€‚
    2. åœ¨æ­£è´Ÿæ ·æœ¬éƒ½è¶³å¤Ÿå¤šä¸”æ¯”ä¾‹ä¸æ˜¯ç‰¹åˆ«æ‚¬æ®Šçš„æƒ…å†µä¸‹ï¼Œåº”è¯¥è€ƒè™‘é‡‡æ ·çš„æ–¹æ³•æˆ–è€…æ˜¯åŠ æƒçš„æ–¹æ³•ã€‚
* Types Of Machine Learning Algorithms
** Learning Style
*** Supervised Learning
    ä»ç»™å®šçš„è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ å‡ºä¸€ä¸ªå‡½æ•°ï¼Œå½“æ–°çš„æ•°æ®åˆ°æ¥æ—¶ï¼Œå¯ä»¥æ ¹æ®è¿™ä¸ªå‡½æ•°é¢„æµ‹ç»“æœã€‚ç›‘ç£å­¦ä¹ çš„è®­ç»ƒé›†éœ€è¦åŒ…æ‹¬è¾“å…¥å’Œè¾“å‡ºï¼Œä¹Ÿå¯ä»¥è¯´æ˜¯ç‰¹å¾å’Œç›®æ ‡ã€‚è®­ç»ƒé›†ä¸­çš„ç›®æ ‡æ˜¯ç”±äººæ ‡æ³¨çš„ã€‚å¸¸è§çš„ç›‘ç£å¼å­¦ä¹ ç®—æ³•åŒ…æ‹¬å›å½’åˆ†æå’Œç»Ÿè®¡åˆ†ç±»ã€‚ [fn:1]  [fn:4]
    #+CAPTION: Supervised Learning WorkFlow
    [[./figures/SupervisedLearning1.png]]

**** Application Scenarios

     Regression, Classification
**** Procedure

     1. å†³å®šèŒƒä¾‹è®­ç»ƒèµ„æ–™çš„å½¢æ€
     2. æœç´¢è®­ç»ƒèµ„æ–™
     3. å†³å®šå­¦ä¹ å‡½æ•°çš„è¾“å…¥ç‰¹å¾çš„è¡¨ç¤ºæ³•
     4. å†³å®šè¦å­¦ä¹ çš„å‡½æ•°, ä»¥åŠå‡½æ•°çš„æ‰€ä½¿ç”¨çš„èµ„æ–™ç»“æ„
     5. å®Œæˆè®¾è®¡
     6. è¯„ä¼°å®é™…å­¦ä¹ å‡ºçš„å‡½æ•°
**** Common Algorithms

     é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰å’Œåå‘ä¼ é€’ç¥ç»ç½‘ç»œï¼ˆBack Propagation Neural Networkï¼‰
     - ArtifiCial Neural Network
     - Naive Bayes
     - Support Vector Machines (SVM)
     - Linear Regression
     - Decision Trees
     - Nearest Neighbor
     - K-Nearest Neighbors
*** Unsupervised Learning
    ä¸ç›‘ç£å­¦ä¹ ç›¸æ¯”ï¼Œè®­ç»ƒé›†æ²¡æœ‰äººä¸ºæ ‡æ³¨çš„ç»“æœã€‚å­¦ä¹ æ¨¡å‹æ˜¯ä¸ºäº†æ¨æ–­å‡ºæ•°æ®çš„ä¸€äº›å†…åœ¨ç»“æ„ã€‚

    These algorithms try to use techniques on the input data to mine for rules, detect patterns, and summarize and group the data points which help in deriving meaningful insights and describe the data better to the users.
**** Application Scenarios

     Clustering
**** Common Algorithms

     - K-Means Clustering
     - Bisecting K-means
     - Hierarchical Clustering
     - Anomaly Detection
     - Association Rules
       + Apriori
       + FP Growth
     - Approaches For Learning Latent Variable Models
       + Expectationâ€“maximization algorithm (EM)
     - BLind Signal Separation Techniques
       + Principal Component Analysis
       + Independent Component Analysis
       + Non-Negative Matrix Factorization
       + Singular Value Decomposition
*** Semi-Supervised Learning
   Input data is a mixture of labelled and unlabelled examples. There is a desired prediction problem but the model must learn the structures to organize the data as well as make predictions.

   Application Scenariosï¼šRegression, Classification

   ç®—æ³•åŒ…æ‹¬ä¸€äº›å¯¹å¸¸ç”¨ç›‘ç£å¼å­¦ä¹ ç®—æ³•çš„å»¶ä¼¸ï¼Œè¿™äº›ç®—æ³•é¦–å…ˆè¯•å›¾å¯¹æœªæ ‡è¯†æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå†å¯¹æ ‡è¯†çš„æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚å¦‚å›¾è®ºæ¨ç†ç®—æ³•ï¼ˆGraph Inferenceï¼‰æˆ–è€…æ‹‰æ™®æ‹‰æ–¯æ”¯æŒå‘é‡æœºï¼ˆLaplacian SVM.ï¼‰ç­‰ã€‚
*** Reinforcement Learning
    Reinforcement Learning allows machines and software agents to automatically determine the ideal behavior within a specific context, in order to maximize its performance. Simple reward feedback is required for the agent to learn its behavior; this is known as the reinforcement signal. [fn:2]
     #+CAPTION: Reinforcement Learning state graph
     #+NAME: sec2.rl
     [[./figures/ReinforcementLearning1.png]]

     In the problem, an agent is supposed decide the best action to select based on his current state. When this step is repeated, the problem is known as a Markov Decision Process.

     In order to produce intelligent programs (also called agents), reinforcement learning goes through the following steps:
      - Input state is observed by the agent.
      - Decision making function is used to make the agent perform an action.
      - After the action is performed, the agent receives reward or reinforcement from the environment.
      - The state-action pair information about the reward is stored.
**** Common Algorithms
     - Q-Learning
     - TD(Temporal Difference)
     - Deep Adversarial Networks
** Algorithms Grouped By Similarity
*** Regression

    Regression Algorithms is concerned with modeling the relationship between variables. That we use to refine using a measure of error in the predictions made by the model[fn:3].
**** Common Algorithms
     - Ordinary Least Squares Regression (OLSR)
     - Linear Regression
     - Logistic Regression
     - Stepwise Regression
     - Multivariate Adaptive Regression Splines (MARS)
     - Locally Estimated Scatterplot Smoothing (LOESS)
*** Instance-based
    This model is a decision problem with instances training data. That is deemed important or required to the model. Such methods build up a database of example data. And it needs to compare new data to the database. For comparison, we use a similarity measure to find the best match and make a prediction.
**** Common Algorithms
     - k-Nearest Neighbor (kNN)
     - Learning Vector Quantization (LVQ)
     - Self-Organizing Map (SOM)
     - Locally Weighted Learning (LWL)

*** Regularization
    A generally simple modifications made to other methods. That is penalizing models which relate to their complexity. Also, favoring simpler models that are also better at generalizing.

**** Common Algorithms
     - Ridge Regression
     - Least Absolute Shrinkage and Selection Operator (LASSO)
     - Elastic Net
     - Least-Angle Regression (LARS)
*** Decision Tree
    Decision tree methods construct a model of decisions. That is made based on the actual values of attributes in the data. Decision trees are trained on data for classification and regression problems. Decision trees are often fast and accurate and a big favorite in Machine Learning.
**** Common Algorithms
     - Classification and Regression Tree (CART)
     - Iterative Dichotomiser 3 (ID3)
     - C4.5 and C5.0 (different versions of a powerful approach)
     - Chi-squared Automatic Interaction Detection (CHAID)
     - Decision Stump
     - M5
     - Conditional Decision Trees
*** Bayesian
    These methods are those that apply Bayesâ€™ Theorem for problems.
**** Common Algorithms
     - Naive Bayes
     - Gaussian Naive Bayes
     - Multinomial Naive Bayes
     - Averaged One-Dependence Estimators (AODE)
     - Bayesian Belief Network (BBN)
     - Bayesian Network (BN)
*** Clustering
    Clustering, like regression, describes the class of problem and the class of methods. The Clustering methods are organized by the modeling approaches such as centroid-based and hierarchal. All methods are concerned with using the inherent structures in the data. That is a need to best organize the data into groups of maximum commonality.
**** Common Algorithms
     - k-Means
     - k-Medians
     - Expectation Maximisation (EM)
     - Hierarchical Clustering
*** Association Rule
    Association rule learning methods extract rules. That best explain observed relationships between variables in data. These rules can discover important and useful associations in large multidimensional datasets. That can be exploited by an organization.
**** Common Algorithms
     - Apriori algorithm
     - Eclat algorithm
*** Artificial Neural Network
    These are models that are inspired by the structure of biological neural networks. They are a class of pattern matching. That we use for regression and classification problems. Although, there is an enormous subfield. As it combines hundreds of algorithms and variations.
**** Common Algorithms
     - Perceptron
     - Back-Propagation
     - Hopfield Network
     - Radial Basis Function Network (RBFN)
*** Deep Learning
    Deep Learning methods are a modern update to Artificial Neural Networks. That is exploiting abundant cheap computation. They are concerned with building much larger and more complex neural networks.
**** Common Algorithms
     - Deep Boltzmann Machine (DBM)
     - Deep Belief Networks (DBN)
     - Convolutional Neural Network (CNN)
     - Recurrent neural network(RNN)
     - Stacked Auto-Encoders
*** Dimensionality Reduction
    Generally, it can be useful to visualize dimensional data. Also, we can use it in a supervised learning method. Many of these methods we adopt for use in classification and regression.
**** Common Algorithms
     - Principal Component Analysis (PCA)
     - Principal Component Regression (PCR)
     - Partial Least Squares Regression (PLSR)
     - Sammon Mapping
     - Multidimensional Scaling (MDS)
     - Projection Pursuit
     - Linear Discriminant Analysis (LDA)
     - Mixture Discriminant Analysis (MDA)
     - Quadratic Discriminant Analysis (QDA)
     - Flexible Discriminant Analysis (FDA)
*** Ensemble
    Basically, these methods are models composed of weaker models. Much effort is put into what types of weak learners to combine and the ways in which to combine them. Hence, this is a very powerful class of techniques and as such is very popular.
**** Common AlgorithmsBoosting
     - Bootstrapped Aggregation (Bagging)
     - AdaBoost
     - Stacked Generalization (blending)
     - Gradient Boosting Machines (GBM)
     - Gradient Boosted Regression Trees (GBRT)
     - Random Forest
     - XGBoost
* Math Knowledges
** Curse Of Dimensionality
   å½“ç©ºé—´ç»´åº¦å¢åŠ æ—¶, åˆ†æå’Œç»„ç»‡é«˜ç»´ç©ºé—´, ä¼šå› ä½“ç§¯çš„æŒ‡æ•°å¢åŠ è€Œé‡åˆ°å„ç§é—®é¢˜. å½“ç©ºé—´ä½“ç§¯å¢åŠ å¤ªå¿«, ä¼šä½¿å¯ç”¨æ•°æ®å˜å¾—éå¸¸ç¨€ç–. å½“æ•°æ®å˜å¾—éå¸¸ç¨€ç–å, ä»å¾ˆå¤šè§’åº¦åˆ†æéƒ½ä¸ç›¸ä¼¼, å› ä¸ºå¸¸ä½¿æ•°æ®ç»„ç»‡ç­–ç•¥å˜å¾—ä½æ•ˆ
** Measuring Similarity and Distance
   In statistics and related fields, a similarity measure or similarity function is a real-valued function that quantifies the similarity between two objects[fn:11][fn:19].

   Similarity measures are in some sense the inverse of distance metrics: they take on large values for similar objects and either zero or a negative value for very dissimilar objects.

   In the context of cluster analysis, Frey and Dueck suggest defining a similarity measure
  \begin{equation}
  \label{eq:4}
  s(x,y)=-\|x-y\|_{2}^{2}
  \tag{6}
  \end{equation}
  where $\|x-y\|_{2}^{2}$ the squared Euclidean distance.

  There are four common setups for similarity and metric distance learning.
    - Regression similarity learning
    - Classification similarity learning
    - Ranking similarity learning
    - Locality sensitive hashing (LSH)
*** Distance Between Numeric Data Points
    When the dimension of a data point is numeric, the general form is called the Minkowski distance.

**** Minkowski Distances
     The Minkowski distance of order p between two points
     \[X=(x_{1},x_{2},\ldots ,x_{n}){\text{ and }}Y=(y_{1},y_{2},\ldots ,y_{n})\in {\mathbb  {R}}^{n}\]
     is defined as
      \begin{equation}
      \label{eq:12}
         D\left(X,Y\right)=\left(\sum _{i=1}^{n}|x_{i}-y_{i}|^{p}\right)^{1/p}
      \end{equation}

      #+CAPTION: unit circles with various values of p
      [[./figures/UnitCirclesInMinkowskiDistance.png]]

      For $p\geq 1$, the Minkowski distance is a metric as a result of the Minkowski inequality. When $p<1$ , the distance between (0,0) and (1,1) is $2^{1/p}>2$ , but the point (0,1) is at a distance 1 from both of these points. Since this violates the triangle inequality, for $p<1$ it is not a metric.

      If the value along the x-dimension is much bigger than the value along the y-dimension?  We need to bring all of them down to scale first.  A common way is to perform a z-transform where each data point first subtracts the mean value, then divides the standard deviation.
      (x_1, y_1) becomes ( (x_1 â€“ Î¼_x)/Ïƒ_x , (y_1 â€“ Î¼_y)/Ïƒ_y )

      This measure, although taking into consideration the distribution of each dimension, assumes the dimensions are independent of each other. But what if the x-dimension has some correlation with the y-dimension? To consider correlations between different dimensions, we use this *Mahalanobis distance*.

      ç®€å•è¯´æ¥ï¼Œé—µæ°è·ç¦»çš„ç¼ºç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼š(1)å°†å„ä¸ªåˆ†é‡çš„é‡çº²(scale)ï¼Œä¹Ÿå°±æ˜¯â€œå•ä½â€å½“ä½œç›¸åŒçš„çœ‹å¾…äº†ã€‚(2)æ²¡æœ‰è€ƒè™‘å„ä¸ªåˆ†é‡çš„åˆ†å¸ƒï¼ˆæœŸæœ›ï¼Œæ–¹å·®ç­‰)å¯èƒ½æ˜¯ä¸åŒçš„ã€‚
**** Euclidean Distance
     When Minkowski distances p = 2, this is equivalent to Euclidean distance[fn:14]
\begin{equation}
\label{eq:14}
{\begin{aligned}d(\mathbf {p} ,\mathbf {q} )=d(\mathbf {q} ,\mathbf {p} )&={\sqrt {(q_{1}-p_{1})^{2}+(q_{2}-p_{2})^{2}+\cdots +(q_{n}-p_{n})^{2}}}\\[8pt]&={\sqrt {\sum _{i=1}^{n}(q_{i}-p_{i})^{2}}}.\end{aligned}}
\end{equation}
**** Manhattan Distance
     When Minkowski distances p = 1, this is equivalent to Euclidean distance[fn:15]
    \begin{equation}
    \label{eq:15}
       d_{1}(\mathbf {p} ,\mathbf {q} )=\|\mathbf {p} -\mathbf {q} \|_{1}=\sum _{i=1}^{n}|p_{i}-q_{i}|,
    \end{equation}
**** Mahalanobis Distance
     The Mahalanobis distance is a measure of the distance between a point P and a distribution D.It is a multi-dimensional generalization of the idea of measuring how many standard deviations away P is from the mean of D.[fn:16][fn:17][fn:18]

     The Mahalanobis distance of an observation ${\vec {x}}=(x_{1},x_{2},x_{3},\dots ,x_{N})^{T}$ from a set of observations with mean ${\vec {\mu }}=(\mu _{1},\mu _{2},\mu _{3},\dots ,\mu _{N})^{T}$ and covariance matrix S is defined as:

\begin{equation}
\label{eq:16}
D_{M}({\vec {x}})={\sqrt {({\vec {x}}-{\vec {\mu }})^{T}S^{-1}({\vec {x}}-{\vec {\mu }})}}.
\end{equation}


    é©¬æ°è·ç¦»æœ‰å¾ˆå¤šä¼˜ç‚¹ï¼Œé©¬æ°è·ç¦»ä¸å—é‡çº²çš„å½±å“ï¼Œä¸¤ç‚¹ä¹‹é—´çš„é©¬æ°è·ç¦»ä¸åŸå§‹æ•°æ®çš„æµ‹é‡å•ä½æ— å…³ï¼›ç”±æ ‡å‡†åŒ–æ•°æ®å’Œä¸­å¿ƒåŒ–æ•°æ®(å³åŸå§‹æ•°æ®ä¸å‡å€¼ä¹‹å·®ï¼‰è®¡ç®—å‡ºçš„äºŒç‚¹ä¹‹é—´çš„é©¬æ°è·ç¦»ç›¸åŒã€‚é©¬æ°è·ç¦»è¿˜å¯ä»¥æ’é™¤å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§çš„å¹²æ‰°ã€‚

â€ƒ  å®ƒçš„ç¼ºç‚¹æ˜¯å¤¸å¤§äº†å˜åŒ–å¾®å°çš„å˜é‡çš„ä½œç”¨ã€‚
**** Cosine Distance
     If we care about the direction of the data rather than the magnitude, then using the cosine distance is a common approach.

     Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.[fn:20]

\begin{equation}
\label{eq:17}
     \mathbf {A} \cdot \mathbf {B} =\left\|\mathbf {A} \right\|\left\|\mathbf {B} \right\|\cos \theta
\end{equation}

\begin{equation}
\label{eq:18}
{\text{similarity}}=\cos(\theta )={\mathbf {A} \cdot \mathbf {B}  \over \|\mathbf {A} \|\|\mathbf {B} \|}={\frac {\sum \limits _{i=1}^{n}{A_{i}B_{i}}}{{\sqrt {\sum \limits _{i=1}^{n}{A_{i}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{B_{i}^{2}}}}}}
\end{equation}

    å¤¹è§’ä½™å¼¦å–å€¼èŒƒå›´ä¸º[-1,1]ã€‚å¤¹è§’ä½™å¼¦è¶Šå¤§è¡¨ç¤ºä¸¤ä¸ªå‘é‡çš„å¤¹è§’è¶Šå°ï¼Œå¤¹è§’ä½™å¼¦è¶Šå°è¡¨ç¤ºä¸¤å‘é‡çš„å¤¹è§’è¶Šå¤§ã€‚å½“ä¸¤ä¸ªå‘é‡çš„æ–¹å‘é‡åˆæ—¶å¤¹è§’ä½™å¼¦å–æœ€å¤§å€¼ 1ï¼Œå½“ä¸¤ä¸ªå‘é‡çš„æ–¹å‘å®Œå…¨ç›¸åå¤¹è§’ä½™å¼¦å–æœ€å°å€¼-1ã€‚
*** Distance Between Categorical Data Points
**** Hamming Distance
     In information theory, the Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different.[fn:21]  In other words, it measures the minimum number of substitutions required to change one string into the other, or the minimum number of errors that could have transformed one string into the other.

     The minimum Hamming distance is used to define some essential notions in coding theory, such as *error detecting and error correcting codes*.

     #+BEGIN_SRC python
       def hamming_distance(s1, s2):
           """Return the Hamming distance between equal-length sequences"""
           if len(s1) != len(s2):
               raise ValueError("Undefined for sequences of unequal length")
           return sum(el1 != el2 for el1, el2 in zip(s1, s2))
     #+END_SRC

   åº”ç”¨ï¼šä¿¡æ¯ç¼–ç ï¼ˆä¸ºäº†å¢å¼ºå®¹é”™æ€§ï¼Œåº”ä½¿å¾—ç¼–ç é—´çš„æœ€å°æ±‰æ˜è·ç¦»å°½å¯èƒ½å¤§ï¼‰ã€‚
**** Jaccard Similarity
     *However, in some cases, equality of certain values don't mean anything*. For example, let's say the data point represents a user with attributes representing each movie. The data point contains a high dimensional binary value indicating that the user has or has not seen the movie (1 represent yes and 0 represent no). Given that most users only see a small portion of all movies, if both users haven't seen a particular movie (a value of 0 for both), it doesn't indicate a similarity between the users. On the other hand, if both users saw the same movie (a value of 1 for each), it is implied that the users have many similarities. In this case, equality of 1 should carry a much higher weight than equality of 0. This leads to the *Jaccard similarity*

     The Jaccard index, also known as Intersection over Union and the Jaccard similarity coefficient, is a statistic used for *comparing the similarity and diversity of sample sets*.[fn:22]

    \begin{equation}
    \label{eq:19}
      J(A,B) = {{|A \cap B|}\over{|A \cup B|}} = {{|A \cap B|}\over{|A| + |B| - |A \cap B|}}
    \end{equation}

    (If A and B are both empty, we define J(A,B) = 1.)  \[ 0\le J(A,B)\le 1 \]

    Whether or not values are matching, though, /if the category is structured as a Tree hierarchy, then the distance between the two categories can be quantified by the path length of their common parent/. For example, "/product/spot/ballgame/basketball" is closer to "/product/spot/ballgame/soccer/shoes" than "/product/luxury/handbags" because the common parent has a longer path.
*** Distance between mixed categorical and numeric data points
    When the data point contains a mixture of numeric and categorical attributes, we can calculate the distance of each group and then treat each measure of distance as a separate dimension (numeric value).

    distance_{final} = Î±.distance_{numeric} + (1- Î±).distance_{categorical}
*** Distance Between Sequence (String, Timeseries)
    In case each attribute represents an element of a sequence, we need a different way to measure the distance. For example, let's say each data point is a string (which contains a sequence of characters) â€” then edit distance[fn:23] is a common measuring tool.

    Basically, edit distance reveals how many "modifications" (which can be insert, modify, delete) are needed to change stringA into stringB. This is usually calculated by using thedynamic programming technique.
****  Edit Distance
     In computational linguistics and computer science, edit distance is a way of quantifying how dissimilar two strings (e.g., words) are to one another by counting the minimum number of operations required to transform one string into the other.
     Using Levenshtein's original operations[fn:24], the edit distance between $a=a_{1}\ldots a_{n} a = a_1\ldots a_n$ and $b=b_{1}\ldots b_{m} b = b_1\ldots b_m$ is given by $d_{mn}$, defined by the recurrence
\begin{align}
\label{eq:21}
d_{{i0}}&=\sum _{{k=1}}^{{i}}w_{{\mathrm  {del}}}(b_{{k}}),&&\quad {\text{for}}\;1\leq i\leq m\\d_{{0j}}&=\sum _{{k=1}}^{{j}}w_{{\mathrm  {ins}}}(a_{{k}}),&&\quad {\text{for}}\;1\leq j\leq n\\d_{{ij}}&={\begin{cases}d_{{i-1,j-1}}&{\text{for}}\;a_{{j}}=b_{{i}}\\\min {\begin{cases}d_{{i-1,j}}+w_{{\mathrm  {del}}}(b_{{i}})\\d_{{i,j-1}}+w_{{\mathrm  {ins}}}(a_{{j}})\\d_{{i-1,j-1}}+w_{{\mathrm  {sub}}}(a_{{j}},b_{{i}})\end{cases}}&{\text{for}}\;a_{{j}}\neq b_{{i}}\end{cases}}&&\quad {\text{for}}\;1\leq i\leq m,1\leq j\leq n
\end{align}
    This algorithm has a time complexity of Î˜(mn). When the full dynamic programming table is constructed, its space complexity is also Î˜(mn); this can be improved to Î˜(min(m,n)) by observing that at any instant, the algorithm only requires two rows (or two columns) in memory. However, this optimization makes it impossible to read off the minimal series of edit operations.[3] A linear-space solution to this problem is offered by *Hirschberg's algorithm*
*** TODO Distance Between Nodes In A Network
*** TODO Distance Between Population Distribution

* Loss Functions
  A loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some "cost" associated with the event. An optimization problem seeks to minimize a loss function. An objective function is either a loss function or its negative (in specific domains, variously called a reward function, a profit function, a utility function, a fitness function, etc.), in which case it is to be maximized. \cite{wiki:Loss_function} \cite{github:loss_function}

  [[http://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote10.html][Empirical Risk Minimization]]
** Regression Loss
*** Mean Squared Error(MSE) / L2 Loss
 \begin{equation}
 \label{eq:22}
 \operatorname {MSE} ={\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}.
 \end{equation}

   The MSE can be written as the sum of the variance of the estimator and the squared bias of the estimator
\begin{equation}
\label{eq:23}
\operatorname {MSE} ({\hat {\theta }})=\operatorname {Var} _{\hat {\theta }}({\hat {\theta }})+\operatorname {Bias} ({\hat {\theta }},\theta )^{2}.
\end{equation}
*** Mean Absolute Error(MAE) /L1 Loss

\begin{equation}
\label{eq:24}
\mathrm {MAE} ={\frac {\sum _{i=1}^{n}\left|y_{i}-x_{i}\right|}{n}}={\frac {\sum _{i=1}^{n}\left|e_{i}\right|}{n}}.
\end{equation}
**** MSE VS MAE  \cite{reg_loss_func}
     *In short, using the squared error is easier to solve, but using the absolute error is more robust to outliers*.

     Since MSE squares the error (yâ€Šâ€”â€Šy_predicted = e), the value of error (e) increases a lot if e > 1. This will make the model with MSE loss give more weight to outliers than a model with MAE loss.

     MAE loss is useful if the training data is corrupted with outliers.

     One big problem in using MAE loss (for neural nets especially) is that its gradient is the same throughout, which means the gradient will be large even for small loss values.To fix this, we can use dynamic learning rate which decreases as we move closer to the minima. MSE behaves nicely in this case and will converge even with a fixed learning rate.

     *Deciding which loss function to use*:
     If the outliers represent anomaly that are important for business and should be detected, then we should use MSE. On the other hand, if we believe that the outliers just represent corrupted data, then we should choose MAE as loss.

     L1 loss is more robust to outliers, but its derivatives are not continuous, making it inefficient to find the solution. L2 loss is sensitive to outliers, but gives a more stable and closed form solution.

     [[http://rishy.github.io/ml/2015/07/28/l1-vs-l2-loss/][L1 vs. L2 Loss function]]

     *Problems with both*: There can be cases where neither loss function gives desirable predictions. For example, if 90% of observations in our data have true target value of 150 and the remaining 10% have target value between 0â€“30. Then a model with MAE as loss might predict 150 for all observations, ignoring 10% of outlier cases, as it will try to go towards median value. In the same case, a model using MSE would give many predictions in the range of 0 to 30 as it will get skewed towards outliers. Both results are undesirable in many business cases.

     What to do in such a case? An easy fix would be to transform the target variables. Another way is to try a different loss function. This is the motivation behind our 3rd loss function, *Huber loss*.
*** Huber Loss
    In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss.

    \begin{equation}
    \label{eq:25}
        L_{\delta }(y,f(x))={\begin{cases}{\frac  {1}{2}}(y-f(x))^{2}&{\textrm  {for}}|y-f(x)|\leq \delta ,\\\delta \,|y-f(x)|-{\frac  {1}{2}}\delta ^{2}&{\textrm  {otherwise.}}\end{cases}}
    \end{equation}

    Itâ€™s basically absolute error, which becomes quadratic when error is small. How small that error has to be to make it quadratic depends on a hyperparameter, ğ›¿ (delta), which can be tuned. *Huber loss approaches MAE when ğ›¿ ~ 0 and MSE when ğ›¿ ~ âˆ (large numbers.)*

    Itâ€™s more robust to outliers than MSE. Therefore, it combines good properties from both MSE and MAE. However, the problem with Huber loss is that we might need to train hyperparameter delta which is an iterative process.
*** Log cosh Loss
    Advantage: log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x. This means that 'logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction. It has all the advantages of Huber loss, and *itâ€™s twice differentiable everywhere*, unlike Huber loss.

    But Log-cosh loss isnâ€™t perfect. It still suffers from the problem of gradient and hessian for very large off-target predictions being constant, therefore resulting in the absence of splits for XGBoost.
*** TODO Quantile Loss
    Quantile loss functions turns out to be useful when we are interested in predicting an interval instead of only point predictions.
** Classification Loss
*** Log Loss (Cross Entropy Loss)
    In information theory, the cross entropy between two probability distributions $p$ and $q$ over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an "artificial" probability distribution $q$, rather than the "true" distribution $p$.

    Logistic loss:  \cite{wiki:classification_loss_func}
    \[ V(f({\vec  {x}}),y)={\frac  {1}{\ln 2}}\ln(1+e^{{-yf({\vec  {x}})}}) \]
    \[ log(1+e^{âˆ’h_{w}(x_{i})y_{i}}) \]

    Cross entropy loss (Log Loss):
    \[ V(f(\vec{x}),t) = -t\ln(f(\vec{x}))-(1-t)\ln(1-f(\vec{x})) \]

    Entropy:
    \[ \mathrm {H} (X)=-\sum _{i=1}^{n}{\mathrm {P} (x_{i})\log _{b}\mathrm {P} (x_{i})} \]
    The conditional entropy of $Y$ given $X$ is defined as
    \[ \mathrm {H} (Y|X)\ =-\sum _{x\in {\mathcal {X}},y\in {\mathcal {Y}}}p(x,y)\log {\frac {p(x,y)}{p(x)}} \]

    For discrete probability distributions $p$ and $q$ with the same support $\mathcal {X}$ this means
    \[ H(p,q)=-\sum _{x\in {\mathcal {X}}}p(x)\,\log q(x) \]
    Let $P$ and $Q$ be probability density functions of $p$ and $q$ with respect to $r$. Then
    \[ H(p,q)=-\int _{\mathcal {X}}P(x)\,\log Q(x)\,dr(x) \]

*** Kullback-Leibler(KL) Divergence
*** Hinge Loss
    In machine learning, the hinge loss is a loss function used for training classifiers.
    \[ \ell(y) = \max(0, 1-t \cdot y) \]
*** Exponential Loss
    It penalizes incorrect predictions more than Hinge loss and has a larger gradient.
    \[ V(f({\vec {x}}),y)=e^{-\beta yf({\vec {x}})} \]

** Others
*** Likelihood Loss
*** Gold Standard Loss(0-1 loss)
    In statistics and decision theory, a frequently used loss function is the 0-1 loss function:
 \begin{equation}
 \label{eq:13}
 L(\hat{y}, y) = I(\hat{y} \ne y)
 \end{equation}

 where $I$ is the [[https://en.wikipedia.org/wiki/Indicator_function][indicator notation]].

 \begin{equation}
 \label{eq:20}
 \mathbf {1} _{A}(x):={\begin{cases}1&{\text{if }}x\in A,\\0&{\text{if }}x\notin A.\end{cases}}
 \end{equation}
*** Perceptron Loss
** TODO Advantage And Disadvantage Of Every Loss Functions
* Optimization
* Performance Measures for Machine Learning
  The metrics that you choose to evaluate your machine learning model is very important. Choice of metrics influences how the performance of machine learning algorithms is measured and compared.[fn:7]

  - Classification Accuracy
  - Logarithmic Loss
  - Confusion Matrix
  - Area under Curve
  - F1 Score
  - Mean Absolute Error
  - Mean Squared Error
** Confusion Matrix
   In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix[fn:6].

   |                    | Actual Positive | Actual Negative |
   |--------------------+-----------------+-----------------|
   | Predicted Positive | TP              | FP              |
   | Predicted Negative | FN              | TN              |

   #+CAPTION: Confusion Matrix 1
  [[./figures/Confusion Matrix 1.png]]


   #+CAPTION: Confusion Matrix 2
   [[./figures/ConfusionMatrix.png]]

   - True Positives :: The cases in which we predicted YES and the actual output was also YES.
   - True Negatives :: The cases in which we predicted NO and the actual output was NO.
   - False Positives :: The cases in which we predicted YES and the actual output was NO.
   - False Negatives :: The cases in which we predicted NO and the actual output was YES.

   When to minimise what?  \\
   Thereâ€™s no hard rule that says what should be minimised in all the situations. It purely depends on the business needs and the context of the problem you are trying to solve. Based on that, we might want to minimise either False Positives or False negatives.

   1. Minimising False Negatives
      Missing a cancer patient will be a huge mistake as no further examination will be done on them. So minimising False Negative is more important.
   2. Minimising False Positives
      In case of Spam email classification, minimising False positives is more important than False Negatives.
** Classification Performance Metrics
*** accuracy (ACC)

\begin{equation}
\label{eq:1}
\mathrm {ACC} ={\frac {\mathrm {TP} +\mathrm {TN} }{P+N}}={\frac {\mathrm {TP} +\mathrm {TN} }{\mathrm {TP} +\mathrm {TN} +\mathrm {FP} +\mathrm {FN} }}
\tag{1}
\end{equation}

  - When to use Accuracy: Accuracy is a good measure when the target variable classes in the data are nearly balanced.[fn:8]
  - When NOT to use Accuracy: Accuracy should *NEVER* be used as a measure when the target variable classes in the data are a majority of one class.
*** Logarithmic Loss

\begin{equation}
\label{eq:2}
LogarithmicLoss = \frac{-1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M}y_{ij}*log(p_{ij})
\tag{2}
\end{equation}
  where,
   - $y_{ij}$, indicates whether sample i belongs to class j or not
   - $p_{ij}$, indicates the probability of sample i belonging to class j
   Log Loss has no upper bound and it exists on the range [0, âˆ). Log Loss nearer to 0 indicates higher accuracy, whereas if the Log Loss is away from 0 then it indicates lower accuracy.

    In general, minimising Log Loss gives greater accuracy for the classifier.
*** Precision or Positive Predictive Value (PPV)
    Precision is a measure that the proportion of prediction true positives in all the prediction positives.

\begin{equation}
\label{eq:3}
\mathrm {PPV} ={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FP} }}
\tag{3}
\end{equation}
*** Recall,  Sensitivity or  True Positive Rate(TPR)
    Recall is a measure that the proportion of prediction true positives in all the actual positives.

\begin{equation}
\label{eq:TPR}
\mathrm {TPR} ={\frac {\mathrm {TP} }{P}}={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FN} }}=1-\mathrm {FNR}
\tag{4}
\end{equation}

    When to use Precision and When to use Recall?
    - *Precision* is about being precise. So even if we managed to capture only one cancer case, and we captured it correctly, then we are 100% precise.
    - *Recall* is not so much about capturing cases correctly but more about capturing all cases that have â€œcancerâ€ with the answer as â€œcancerâ€. So if we simply always say every case as â€œcancerâ€, we have 100% recall.

*** ROC & AUC
    ROC(Receiver Operating Characteristic)

    AUC(Area Under Curve)

    åœ¨ä¸åŒçš„åº”ç”¨ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å¯æ ¹æ®ä»»åŠ¡éœ€æ±‚æ¥é‡‡ç”¨ä¸åŒçš„é˜ˆå€¼ã€‚ä¾‹å¦‚ï¼Œè‹¥æˆ‘ä»¬æ›´é‡è§†â€œæŸ¥å‡†ç‡â€(Precision)ï¼Œåˆ™å¯ä»¥æŠŠé˜ˆå€¼è®¾ç½®çš„å¤§ä¸€äº›ï¼Œè®©åˆ†ç±»å™¨çš„é¢„æµ‹ç»“æœæ›´æœ‰æŠŠæ¡ï¼›è‹¥æˆ‘ä»¬æ›´é‡è§†â€œæŸ¥å…¨ç‡â€(Recall)ï¼Œåˆ™å¯ä»¥æŠŠé˜ˆå€¼è®¾ç½®çš„å°ä¸€äº›ï¼Œè®©åˆ†ç±»å™¨é¢„æµ‹å‡ºæ›´å¤šçš„æ­£ä¾‹ã€‚
     *ROCæ›²çº¿åˆ™æ˜¯ä»é˜ˆå€¼é€‰å–è§’åº¦å‡ºå‘æ¥ç ”ç©¶å­¦ä¹ å™¨æ³›åŒ–æ€§èƒ½çš„æœ‰åŠ›å·¥å…·*.
**** ROC
     The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.[fn:9]

     the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from $-\infty$ to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis.
     *FPR \ref{eq:TPR} on the x-axis and TPR \ref{eq:FPR} on the y-axis*.
     #+CAPTION: ROC curve
     [[./figures/ROC.png]]

    \begin{equation}
    \label{eq:FPR}
    \mathrm {FPR} ={\frac {\mathrm {FP} }{N}}={\frac {\mathrm {FP} }{\mathrm {FP} +\mathrm {TN} }}=1-\mathrm {TNR}
    \tag{5}
    \end{equation}
     ROC space and Curves in ROC space.[fn:9]


     ä¸»è¦ä½œç”¨:
      1. ROCæ›²çº¿èƒ½å¾ˆå®¹æ˜“çš„æŸ¥å‡ºä»»æ„é˜ˆå€¼å¯¹å­¦ä¹ å™¨çš„æ³›åŒ–æ€§èƒ½å½±å“ã€‚
      2.æœ‰åŠ©äºé€‰æ‹©æœ€ä½³çš„é˜ˆå€¼ã€‚ROCæ›²çº¿è¶Šé è¿‘å·¦ä¸Šè§’ï¼Œæ¨¡å‹çš„å‡†ç¡®æ€§å°±è¶Šé«˜ã€‚æœ€é è¿‘å·¦ä¸Šè§’çš„ROCæ›²çº¿ä¸Šçš„ç‚¹æ˜¯åˆ†ç±»é”™è¯¯æœ€å°‘çš„æœ€å¥½é˜ˆå€¼ï¼Œå…¶å‡æ­£ä¾‹å’Œå‡åä¾‹æ€»æ•°æœ€å°‘ã€‚
      3.å¯ä»¥å¯¹ä¸åŒçš„å­¦ä¹ å™¨æ¯”è¾ƒæ€§èƒ½ã€‚å°†å„ä¸ªå­¦ä¹ å™¨çš„ROCæ›²çº¿ç»˜åˆ¶åˆ°åŒä¸€åæ ‡ä¸­ï¼Œç›´è§‚åœ°é‰´åˆ«ä¼˜åŠ£ï¼Œé è¿‘å·¦ä¸Šè§’çš„ROCæ›²æ‰€ä»£è¡¨çš„å­¦ä¹ å™¨å‡†ç¡®æ€§æœ€é«˜ã€‚
     ä¼˜ç‚¹:
     - è¯¥æ–¹æ³•ç®€å•ã€ç›´è§‚ã€é€šè¿‡å›¾ç¤ºå¯è§‚å¯Ÿåˆ†æå­¦ä¹ å™¨çš„å‡†ç¡®æ€§ï¼Œå¹¶å¯ç”¨è‚‰çœ¼ä½œå‡ºåˆ¤æ–­ã€‚ROCæ›²çº¿å°†çœŸæ­£ä¾‹ç‡å’Œå‡æ­£ä¾‹ç‡ä»¥å›¾ç¤ºæ–¹æ³•ç»“åˆåœ¨ä¸€èµ·ï¼Œå¯å‡†ç¡®åæ˜ æŸç§å­¦ä¹ å™¨çœŸæ­£ä¾‹ç‡å’Œå‡æ­£ä¾‹ç‡çš„å…³ç³»ï¼Œæ˜¯æ£€æµ‹å‡†ç¡®æ€§çš„ç»¼åˆä»£è¡¨ã€‚
     - ROCæ›²çº¿ä¸å›ºå®šé˜ˆå€¼ï¼Œå…è®¸ä¸­é—´çŠ¶æ€çš„å­˜åœ¨ï¼Œåˆ©äºä½¿ç”¨è€…ç»“åˆä¸“ä¸šçŸ¥è¯†ï¼Œæƒè¡¡æ¼è¯Šä¸è¯¯è¯Šçš„å½±å“ï¼Œé€‰æ‹©ä¸€ä¸ªæ›´åŠ çš„é˜ˆå€¼ä½œä¸ºè¯Šæ–­å‚è€ƒå€¼ã€‚
**** AUC
     åœ¨è¿›è¡Œå­¦ä¹ å™¨çš„æ¯”è¾ƒæ—¶ï¼Œè‹¥ä¸€ä¸ªå­¦ä¹ å™¨çš„ROCæ›²çº¿è¢«å¦ä¸€ä¸ªå­¦ä¹ å™¨çš„æ›²çº¿å®Œå…¨â€œåŒ…ä½â€ï¼Œåˆ™å¯æ–­è¨€åè€…çš„æ€§èƒ½ä¼˜äºå‰è€…ï¼›è‹¥ä¸¤ä¸ªå­¦ä¹ å™¨çš„ROCæ›²çº¿å‘ç”Ÿäº¤å‰ï¼Œåˆ™éš¾ä»¥ä¸€èˆ¬æ€§çš„æ–­è¨€ä¸¤è€…å­°ä¼˜å­°åŠ£ã€‚æ­¤æ—¶å¦‚æœä¸€å®šè¦è¿›è¡Œæ¯”è¾ƒï¼Œåˆ™æ¯”è¾ƒåˆç†çš„åˆ¤æ–­ä¾æ®æ˜¯æ¯”è¾ƒ *ROCæ›²çº¿ä¸‹çš„é¢ç§¯*.
     TODO fix Mann-Whitney U test[fn:10]

     AUCæ˜¯è¡¡é‡ *äºŒåˆ†ç±»æ¨¡å‹* ä¼˜åŠ£çš„ä¸€ç§è¯„ä»·æŒ‡æ ‡ï¼Œ *è¡¨ç¤ºé¢„æµ‹çš„æ­£ä¾‹æ’åœ¨è´Ÿä¾‹å‰é¢çš„æ¦‚ç‡* ã€‚AUCå’ŒMann-Whitney U test[fn:10](æ›¼-æ…§ç‰¹å°¼Uæ£€éªŒ)æœ‰å¯†åˆ‡çš„è”ç³»ã€‚ä»Mann-Whitney U statisticçš„è§’åº¦æ¥è§£é‡Šï¼ŒAUCå°±æ˜¯ä»æ‰€æœ‰æ­£æ ·æœ¬ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ï¼Œä»æ‰€æœ‰è´Ÿæ ·æœ¬ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ï¼Œç„¶åæ ¹æ®ä½ çš„å­¦ä¹ å™¨å¯¹ä¸¤ä¸ªéšæœºæ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼ŒæŠŠæ­£æ ·æœ¬é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¦‚ç‡ï¼ŒæŠŠè´Ÿæ ·æœ¬é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¦‚ç‡ï¼Œ>çš„æ¦‚ç‡å°±ç­‰äºAUCã€‚æ‰€ä»¥AUCåæ˜ çš„æ˜¯åˆ†ç±»å™¨å¯¹æ ·æœ¬çš„æ’åºèƒ½åŠ›ã€‚

     AUCçš„è®¡ç®—æ–¹æ³•åŒæ—¶è€ƒè™‘äº†å­¦ä¹ å™¨å¯¹äºæ­£ä¾‹å’Œè´Ÿä¾‹çš„åˆ†ç±»èƒ½åŠ›ï¼Œåœ¨æ ·æœ¬ä¸å¹³è¡¡çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶èƒ½å¤Ÿå¯¹åˆ†ç±»å™¨åšå‡ºåˆç†çš„è¯„ä»·ã€‚ *AUCå¯¹æ ·æœ¬ç±»åˆ«æ˜¯å¦å‡è¡¡å¹¶ä¸æ•æ„Ÿ*, è¿™ä¹Ÿæ˜¯ä¸å‡è¡¡æ ·æœ¬é€šå¸¸ç”¨AUCè¯„ä»·å­¦ä¹ å™¨æ€§èƒ½çš„ä¸€ä¸ªåŸå› ã€‚

     åœ¨å¤šåˆ†ç±»é—®é¢˜ä¸‹èƒ½ä¸èƒ½ä½¿ç”¨ROCæ›²çº¿æ¥è¡¡é‡æ¨¡å‹æ€§èƒ½? å¦‚æœç¡®å®éœ€è¦åœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­ç”¨ROCæ›²çº¿çš„è¯ï¼Œå¯ä»¥è½¬åŒ–ä¸ºå¤šä¸ªâ€œä¸€å¯¹å¤šâ€çš„é—®é¢˜ã€‚å³æŠŠå…¶ä¸­ä¸€ä¸ªå½“ä½œæ­£ä¾‹ï¼Œå…¶ä½™å½“ä½œè´Ÿä¾‹æ¥çœ‹å¾…ï¼Œç”»å‡ºå¤šä¸ªROCæ›²çº¿ã€‚
*** F1 Score
    In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy.[fn:12]

    The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.
\begin{equation}
\label{eq:5}
F_{1}=\left({\frac {\mathrm {recall} ^{-1}+\mathrm {precision} ^{-1}}{2}}\right)^{-1}=2\cdot {\frac {\mathrm {precision} \cdot \mathrm {recall} }{\mathrm {precision} +\mathrm {recall} }}
\tag{7}
\end{equation}
    The general formula for positive real Î² is:

\begin{equation}
\label{eq:6}
    F_\beta = (1 + \beta^2) \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}{(\beta^2 \cdot \mathrm{precision}) + \mathrm{recall}}  = \frac {(1 + \beta^2) \cdot \mathrm{true\ positive} }{(1 + \beta^2) \cdot \mathrm{true\ positive} + \beta^2 \cdot \mathrm{false\ negative} + \mathrm{false\ positive}}\,
.
\end{equation}
*** Mean Absolute Error(MAE)
    In statistics, mean absolute error (MAE) is a measure of difference between two continuous variables.

    Mean Absolute Error is the average of the difference between the Original Values and the Predicted Values.

    It gives us the measure of how far the predictions were from the actual output.

    However, they donâ€™t gives us any idea of the direction of the error

    The Mean Absolute Error is given by:

\begin{equation}
\label{eq:7}
    \mathrm {MAE} ={\frac {\sum _{i=1}^{n}\left|y_{i}-x_{i}\right|}{n}}={\frac {\sum _{i=1}^{n}\left|e_{i}\right|}{n}}.
\end{equation}

     The Mean Error is given by:
\begin{equation}
\label{eq:8}
    \mathrm {ME} ={\frac {\sum _{i=1}^{n}y_{i}-x_{i}}{n}}.
\end{equation}
*** Mean Squared Error(MSE)
    In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator measures the average of the squares of the errorsâ€”that is, the average squared difference between the estimated values and what is estimated.

    The advantage of MSE being that it is easier to compute the gradient, whereas Mean Absolute Error requires complicated linear programming tools to compute the gradient. As, we take square of the error, the effect of larger errors become more pronounced then smaller error, hence the model can now focus more on the larger errors.
\begin{equation}
\label{eq:11}
    \operatorname {MSE} ={\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}.
\end{equation}

    TODO: Fix mean squared prediction error[fn:13]

    the MSE is often called the mean squared prediction error[fn:13], and is computed as
\begin{equation}
\label{eq:10}
\operatorname {MSPE} ={\frac {1}{q}}\sum_{i=n+1}^{n+q}(Y_{i}-{\hat {Y_{i}}})^{2}.
\end{equation}


    Proof of variance and bias relationship
\begin{equation}
\label{eq:9}
\begin{aligned}\operatorname {MSE} ({\hat {\theta }})&=\operatorname {E} _{\hat {\theta }}\left[({\hat {\theta }}-\theta )^{2}\right]\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]+\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}\right]\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)^{2}+2\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)+\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}\right]\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)^{2}\right]+\operatorname {E} _{\hat {\theta }}\left[2\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)\right]+\operatorname {E} _{\hat {\theta }}\left[\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}\right]\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)^{2}\right]+2\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)\operatorname {E} _{\hat {\theta }}\left[{\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right]+\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}&&\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta ={\text{const.}}\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)^{2}\right]+2\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)+\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}&&\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]={\text{const.}}\\&=\operatorname {E} _{\hat {\theta }}\left[\left({\hat {\theta }}-\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]\right)^{2}\right]+\left(\operatorname {E} _{\hat {\theta }}[{\hat {\theta }}]-\theta \right)^{2}\\&=\operatorname {Var} _{\hat {\theta }}({\hat {\theta }})+\operatorname {Bias} _{\hat {\theta }}({\hat {\theta }},\theta )^{2}\end{aligned}
\end{equation}
* Ten Examples of Machine Learning Problems
   1. Spam Detection  \\
    Given email in an inbox, identify those email messages that are spam and those that are not.Having a model of this problem would allow a program to leave non-spam emails in the inbox and move spam emails to a spam folder.
   2. Credit Card Fraud Detection  \\
    Given credit card transactions for a customer in a month, identify those transactions that were made by the customer and those that were not. A program with a model of this decision could refund those transactions that were fraudulent.
   3. Digit Recognision  \\
    Given a zip codes hand written on envelops, identify the digit for each hand written character. A model of this problem would allow a computer program to read and understand handwritten zip codes and sort envelops by geographic region.
   4. Speech Understanding  \\
    Given an utterance from a user, identify the specific request made by the user. A model of this problem would allow a program to understand and make an attempt to fulfil that request. The iPhone with Siri has this capability.
   5. Face Detection
    Given a digital photo album of many hundreds of digital photographs, identify those photos that include a given person. A model of this decision process would allow a program to organize photos by person. Some cameras and software like iPhoto has this capability.
   6. Product Recommendation  \\
    Given a purchase history for a customer and a large inventory of products, identify those products in which that customer will be interested and likely to purchase. A model of this decision process would allow a program to make recommendations to a customer and motivate product purchases. Amazon has this capability. Also think of Facebook, GooglePlus and Facebook that recommend users to connect with you after you sign-up.
   7. Medical Diagnosis  \\
    Given the symptoms exhibited in a patient and a database of anonymized patient records, predict whether the patient is likely to have an illness. A model of this decision problem could be used by a program to provide decision support to medical professionals.
   8. Stock Trading  \\
    Given the current and past price movements for a stock, determine whether the stock should be bought, held or sold. A model of this decision problem could provide decision support to financial analysts.
   9. Customer segmentation  \\
    Given the pattern of behaviour by a user during a trial period and the past behaviours of all users, identify those users that will convert to the paid version of the product and those that will not. A model of this decision problem would allow a program to trigger customer interventions to persuade the customer to covert early or better engage in the trial.
   10. Shape Detection  \\
    Given a user hand drawing a shape on a touch screen and a database of known shapes, determine which shape the user was trying to draw. A model of this decision would allow a program to show the platonic version of that shape the user drew to make crisp diagrams. The Instaviz iPhone app does this.

* Algorithms
  [[https://en.wikipedia.org/wiki/List_of_algorithms][List of algorithms]]
** Supervised learning
*** Support Vector Machines
*** linear regression
*** logistic regression
*** naive Bayes
*** linear discriminant analysis
*** decision trees
*** k-nearest neighbor algorithm
*** Neural Networks (Multilayer perceptron)
*** Similarity learning
** Unsupervised learning
*** Clustering
    [[https://en.wikipedia.org/wiki/Cluster_analysis][Cluster analysis]]
**** hierarchical clustering
**** k-means
**** mixture models
**** DBSCAN
**** OPTICS algorithm
*** Anomaly detection
**** Local Outlier Factor
*** Neural Networks
**** Autoencoders
**** Deep Belief Nets
**** Hebbian Learning
**** Generative Adversarial Networks
**** Self-organizing map
*** Approaches for learning latent variable models such as
**** Expectationâ€“maximization algorithm (EM)
**** Method of moments
**** Blind signal separation techniques
***** Principal component analysis
***** Independent component analysis
***** Non-negative matrix factorization
***** Singular value decomposition
** Reinforcement learning
   [[https://en.wikipedia.org/wiki/Reinforcement_learning?action=edit&oldid=876586730&wteswitched=1][Reinforcement learning]]

* FQA

* Footnotes
[fn:24] [[https://en.wikipedia.org/wiki/Levenshtein_distance][wiki Levenshtein distance]]

[fn:23] [[https://en.wikipedia.org/wiki/Edit_distance][wiki Edit distance]]

[fn:22] [[https://en.wikipedia.org/wiki/Jaccard_index][wiki Jaccard index]]

[fn:21] [[https://en.wikipedia.org/wiki/Hamming_distance][wiki Hamming distance]]

[fn:20] [[https://en.wikipedia.org/wiki/Cosine_similarity][wiki Cosine similarity]]

[fn:19] [[https://dzone.com/articles/machine-learning-measuring][Machine Learning: Measuring Similarity and Distance]]

[fn:18] [[https://blog.csdn.net/u010167269/article/details/51627338][æ¬§æ°è·ç¦»ä¸é©¬æ°è·ç¦»]]

[fn:17] [[https://stats.stackexchange.com/questions/62092/bottom-to-top-explanation-of-the-mahalanobis-distance][Bottom to top explanation of the Mahalanobis distance?]]

[fn:16] [[https://en.wikipedia.org/wiki/Mahalanobis_distance][wiki Mahalanobis distance]]

[fn:15] [[https://en.wikipedia.org/wiki/Taxicab_geometry][wiki Taxicab geometry Manhattan Distance]]

[fn:14] [[https://en.wikipedia.org/wiki/Euclidean_distance][wiki Euclidean distance]]

[fn:13] [[https://en.wikipedia.org/wiki/Mean_squared_prediction_error][wiki Mean squared prediction error]]

[fn:12] [[https://en.wikipedia.org/wiki/F1_score][wiki F1 score]]

[fn:11] [[https://en.wikipedia.org/wiki/Similarity_measure][wiki Similarity measure]]

[fn:10] [[https://en.wikipedia.org/wiki/Mann%25E2%2580%2593Whitney_U_test][wiki Mannâ€“Whitney U test]]

[fn:9] [[https://en.wikipedia.org/wiki/Receiver_operating_characteristic][wiki Receiver operating characteristic]]

[fn:8] [[https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b][Performance Metrics for Classification problems in Machine Learning]]

[fn:7] [[https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234][Metrics to Evaluate your Machine Learning Algorithm]]

[fn:6] [[https://en.wikipedia.org/wiki/Confusion_matrix][wiki Confusion matrix]]

[fn:5] [[https://mp.weixin.qq.com/s?__biz=MzI5NDMzMjY1MA==&mid=2247484313&idx=1&sn=568015a62bf99ca5b6bd282b465244be&chksm=ec65321cdb12bb0a772814204ac5f48136c99f44a39ff34f5bde115ab5630948a40f747a39f0&scene=21#wechat_redirect][åˆ†ç±»ä¸­è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜]]

[fn:4] [[http://ai.51cto.com/art/201810/585105.htm][æ•°æ®ç§‘å­¦å®¶é¡»çŸ¥çš„ 19 ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•]]

[fn:3] [[https://dzone.com/articles/top-machine-learning-algorithm-you-should-know-to][Top Machine Learning Algorithms You Should Know to Become a Data Scientist]]

[fn:2] [[https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861][Types of Machine Learning Algorithms You Should Know]]

[fn:1] [[https://en.proft.me/2015/12/24/types-machine-learning-algorithms/][Types of machine learning algorithms]]
